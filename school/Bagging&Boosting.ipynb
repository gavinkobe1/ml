{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N/LAB Machine Learning and Advanced Analytics\n",
    "## Practical 6\n",
    "\n",
    "### Predicting employee attrition via ensemble tree-based methods. \n",
    "\n",
    "The issue of keeping one's employees happy and satisfied is a perennial and age-old challenge. If an employee you have invested so much time and money leaves for \"greener pastures\", then this would mean that you would have to spend even more time and money to hire somebody else. Therefore we turn to our predictive modelling capabilities and see if we can predict employee attrition.\n",
    "\n",
    "The dataset we are going to use is `WA_Fn-UseC_-HR-Employee-Attrition.csv` **(Please upload the file to the same category as the notebook)**.\n",
    "\n",
    "#### The data has the following columns:\n",
    "```\n",
    "Age - numeric                                   Attrition - categorical (output feature)\n",
    "BusinessTravel - categorical                    DailyRate - numeric\n",
    "Department - categorical                        DistanceFromHome - numeric\n",
    "Education - categorical                         EducationField - categorical\n",
    "EmployeeCount - numeric                         EmployeeNumber - numeric\n",
    "EnvironmentSatisfaction - categorical           Gender - categorical\n",
    "HourlyRate - numeric                            JobInvolvement - categorical\n",
    "JobLevel - categorical                          JobRole - categorical\n",
    "JobSatisfaction - categorical                   MaritalStatus - categorical\n",
    "MonthlyIncome - numeric                         MonthlyRate - numeric\n",
    "NumCompaniesWorked - numeric                    Over18 - categorical\n",
    "OverTime - categorical                          PercentSalaryHike - numeric\n",
    "PerformanceRating - categorical                 RelationshipSatisfaction - categorical\n",
    "StandardHours - numeric                         StockOptionLevel - categorical\n",
    "TotalWorkingYears - numeric                     TrainingTimesLastYear - numeric\n",
    "WorkLifeBalance - categorical                   YearsAtCompany - numeric\n",
    "YearsInCurrentRole - numeric                    YearsSinceLastPromotion - numeric\n",
    "YearsWithCurrManager - numeric\n",
    "```\n",
    "\n",
    "**Problem: Predict employee attrition**\n",
    "\n",
    "In this practical, we will implement a **Bagging** and an **Adaptive Boosting** model after we finish categorical encoding and handling the unbalanced class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn then restart to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \n",
    "Let's import modules that will be further used and load the data as a pandas dataframe\n",
    "\n",
    "As always let's call either .head() or .describe() or both to check our load worked like we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data as pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1005</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1324</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1358</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>216</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1299</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "5   32        No  Travel_Frequently       1005  Research & Development   \n",
       "6   59        No      Travel_Rarely       1324  Research & Development   \n",
       "7   30        No      Travel_Rarely       1358  Research & Development   \n",
       "8   38        No  Travel_Frequently        216  Research & Development   \n",
       "9   36        No      Travel_Rarely       1299  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "5                 2          2  Life Sciences              1               8   \n",
       "6                 3          3        Medical              1              10   \n",
       "7                24          1  Life Sciences              1              11   \n",
       "8                23          3  Life Sciences              1              12   \n",
       "9                27          3        Medical              1              13   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "5  ...                         3            80                 0   \n",
       "6  ...                         1            80                 3   \n",
       "7  ...                         2            80                 1   \n",
       "8  ...                         2            80                 0   \n",
       "9  ...                         2            80                 2   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "5                  8                      2               2               7   \n",
       "6                 12                      3               2               1   \n",
       "7                  1                      2               3               1   \n",
       "8                 10                      2               3               9   \n",
       "9                 17                      3               2               7   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "5                  7                        3                     6  \n",
       "6                  0                        0                     0  \n",
       "7                  0                        0                     0  \n",
       "8                  7                        1                     8  \n",
       "9                  7                        7                     7  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check data loaded as we expected\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         False\n",
       "Attrition                   False\n",
       "BusinessTravel              False\n",
       "DailyRate                   False\n",
       "Department                  False\n",
       "DistanceFromHome            False\n",
       "Education                   False\n",
       "EducationField              False\n",
       "EmployeeCount               False\n",
       "EmployeeNumber              False\n",
       "EnvironmentSatisfaction     False\n",
       "Gender                      False\n",
       "HourlyRate                  False\n",
       "JobInvolvement              False\n",
       "JobLevel                    False\n",
       "JobRole                     False\n",
       "JobSatisfaction             False\n",
       "MaritalStatus               False\n",
       "MonthlyIncome               False\n",
       "MonthlyRate                 False\n",
       "NumCompaniesWorked          False\n",
       "Over18                      False\n",
       "OverTime                    False\n",
       "PercentSalaryHike           False\n",
       "PerformanceRating           False\n",
       "RelationshipSatisfaction    False\n",
       "StandardHours               False\n",
       "StockOptionLevel            False\n",
       "TotalWorkingYears           False\n",
       "TrainingTimesLastYear       False\n",
       "WorkLifeBalance             False\n",
       "YearsAtCompany              False\n",
       "YearsInCurrentRole          False\n",
       "YearsSinceLastPromotion     False\n",
       "YearsWithCurrManager        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "We're going to do a standard prediction task so we need to split our data into input features and the output feature. **Let's call them X and y as is convention.**\n",
    "\n",
    "We also need to convert y, to be an integer binary output feature, where **1 represents \"Attrition\" and 0 represents \"Not Attrition\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1465    0\n",
       "1466    0\n",
       "1467    0\n",
       "1468    0\n",
       "1469    0\n",
       "Name: Attrition, Length: 1470, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our input features and our output feature\n",
    "# Call our input features X and our output feature y (the sklearn standard)\n",
    "X = data.drop(columns = 'Attrition')\n",
    "y = data.Attrition\n",
    "\n",
    "# Now we need to encode our output feature to be an integer 0 or 1. \n",
    "# This is because we have a binary classification problem and in order to use sklearn's\n",
    "# built-in evaluation measures we need to have one class defined as 1 (target) and one as 0 (non-target).\n",
    "y.replace(to_replace=\"Yes\", value=1, inplace=True)\n",
    "y.replace(to_replace=\"No\", value=0, inplace=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1233\n",
       "1     237\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the frequency counts of the values of output feature\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Now we should think about evaluation.\n",
    "\n",
    "In this practical, we are going to do the simpliest possible form of evaluation, a single test train split. **You can extend it to a cross validation version by yourself**\n",
    "\n",
    "**NOTE 1:** Since we have an unbalanced target class we need to be careful that we don't accidentally sample all attrtion observations into our training set. Then there will be no positive observation in the testing set. That would make our task way to easy! Therefore we are going to tell the `train_test_split(..)` function to sample in a stratified way based on the class labels.\n",
    "\n",
    "**NOTE 2:** So you can follow along with the solution later I'd recommend a `test_size of 0.20` and a `random_state of 42`. I'd also use the standard names for the output, i.e. `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StratifiedKFold** is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "\n",
    "The stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets as well as for validation and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Encoding categorical features into dummy variables\n",
    "\n",
    "We will use the same **`OneHotEncoder`** that we used before. \n",
    "\n",
    "[The documentation for this package](https://contrib.scikit-learn.org/category_encoders/).\n",
    "\n",
    "**NOTE:** Because the dataset contains categorical features and the method we will use to do oversampling, `SMOTE`, only takes continuous features, we need to encode categorical features before handling the unbalanced class problem unsing `SMOTE`. \n",
    "\n",
    "Another solution is to use `SMOTENC`. It supports categorical features. But the list of categorical features are required to be specified when initiate a `SMOTENC` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "#Initialzie an OneHotEncoder object\n",
    "enc = OneHotEncoder(handle_unknown='value')\n",
    "\n",
    "#Learn and apply the encoding on training set\n",
    "X_train_enc = enc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel_1</th>\n",
       "      <th>BusinessTravel_2</th>\n",
       "      <th>BusinessTravel_3</th>\n",
       "      <th>Department_1</th>\n",
       "      <th>Department_2</th>\n",
       "      <th>Department_3</th>\n",
       "      <th>EducationField_1</th>\n",
       "      <th>EducationField_2</th>\n",
       "      <th>EducationField_3</th>\n",
       "      <th>EducationField_4</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel_1  BusinessTravel_2  BusinessTravel_3  Department_1  \\\n",
       "1194                 1                 0                 0             1   \n",
       "128                  1                 0                 0             0   \n",
       "810                  1                 0                 0             1   \n",
       "478                  1                 0                 0             1   \n",
       "491                  0                 1                 0             0   \n",
       "323                  1                 0                 0             0   \n",
       "258                  1                 0                 0             0   \n",
       "812                  0                 1                 0             0   \n",
       "1132                 1                 0                 0             1   \n",
       "996                  1                 0                 0             1   \n",
       "\n",
       "      Department_2  Department_3  EducationField_1  EducationField_2  \\\n",
       "1194             0             0                 1                 0   \n",
       "128              1             0                 0                 1   \n",
       "810              0             0                 0                 0   \n",
       "478              0             0                 0                 0   \n",
       "491              1             0                 0                 0   \n",
       "323              1             0                 0                 0   \n",
       "258              1             0                 1                 0   \n",
       "812              1             0                 1                 0   \n",
       "1132             0             0                 1                 0   \n",
       "996              0             0                 0                 0   \n",
       "\n",
       "      EducationField_3  EducationField_4  ...  RelationshipSatisfaction  \\\n",
       "1194                 0                 0  ...                         3   \n",
       "128                  0                 0  ...                         3   \n",
       "810                  1                 0  ...                         4   \n",
       "478                  0                 1  ...                         3   \n",
       "491                  0                 1  ...                         2   \n",
       "323                  0                 1  ...                         4   \n",
       "258                  0                 0  ...                         2   \n",
       "812                  0                 0  ...                         3   \n",
       "1132                 0                 0  ...                         3   \n",
       "996                  1                 0  ...                         4   \n",
       "\n",
       "      StandardHours  StockOptionLevel  TotalWorkingYears  \\\n",
       "1194             80                 3                 29   \n",
       "128              80                 1                  3   \n",
       "810              80                 1                 23   \n",
       "478              80                 0                  7   \n",
       "491              80                 1                 10   \n",
       "323              80                 0                  5   \n",
       "258              80                 0                  1   \n",
       "812              80                 1                 18   \n",
       "1132             80                 1                  5   \n",
       "996              80                 0                  6   \n",
       "\n",
       "      TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
       "1194                      2                3               3   \n",
       "128                       2                3               2   \n",
       "810                       3                3              12   \n",
       "478                       1                3               7   \n",
       "491                       3                3               8   \n",
       "323                       4                2               3   \n",
       "258                       0                2               1   \n",
       "812                       1                3               8   \n",
       "1132                      2                3               5   \n",
       "996                       3                3               6   \n",
       "\n",
       "      YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "1194                   2                        1                     2  \n",
       "128                    1                        2                     1  \n",
       "810                    9                        4                     9  \n",
       "478                    4                        0                     6  \n",
       "491                    7                        4                     7  \n",
       "323                    2                        2                     2  \n",
       "258                    0                        0                     0  \n",
       "812                    7                        0                     1  \n",
       "1132                   4                        1                     2  \n",
       "996                    2                        4                     4  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the data encoded as we expected  和原数据对比\n",
    "X_train_enc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel_1</th>\n",
       "      <th>BusinessTravel_2</th>\n",
       "      <th>BusinessTravel_3</th>\n",
       "      <th>Department_1</th>\n",
       "      <th>Department_2</th>\n",
       "      <th>Department_3</th>\n",
       "      <th>EducationField_1</th>\n",
       "      <th>EducationField_2</th>\n",
       "      <th>EducationField_3</th>\n",
       "      <th>EducationField_4</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel_1  BusinessTravel_2  BusinessTravel_3  Department_1  \\\n",
       "1061                 1                 0                 0             1   \n",
       "891                  0                 1                 0             0   \n",
       "456                  0                 1                 0             1   \n",
       "922                  0                 1                 0             0   \n",
       "69                   0                 1                 0             0   \n",
       "...                ...               ...               ...           ...   \n",
       "1269                 0                 1                 0             0   \n",
       "1352                 0                 1                 0             0   \n",
       "1236                 0                 1                 0             1   \n",
       "1023                 0                 1                 0             0   \n",
       "285                  0                 1                 0             0   \n",
       "\n",
       "      Department_2  Department_3  EducationField_1  EducationField_2  \\\n",
       "1061             0             0                 1                 0   \n",
       "891              1             0                 1                 0   \n",
       "456              0             0                 1                 0   \n",
       "922              1             0                 1                 0   \n",
       "69               1             0                 0                 1   \n",
       "...            ...           ...               ...               ...   \n",
       "1269             0             1                 1                 0   \n",
       "1352             1             0                 1                 0   \n",
       "1236             0             0                 0                 0   \n",
       "1023             1             0                 1                 0   \n",
       "285              1             0                 1                 0   \n",
       "\n",
       "      EducationField_3  EducationField_4  ...  RelationshipSatisfaction  \\\n",
       "1061                 0                 0  ...                         3   \n",
       "891                  0                 0  ...                         4   \n",
       "456                  0                 0  ...                         3   \n",
       "922                  0                 0  ...                         4   \n",
       "69                   0                 0  ...                         1   \n",
       "...                ...               ...  ...                       ...   \n",
       "1269                 0                 0  ...                         2   \n",
       "1352                 0                 0  ...                         4   \n",
       "1236                 1                 0  ...                         2   \n",
       "1023                 0                 0  ...                         4   \n",
       "285                  0                 0  ...                         2   \n",
       "\n",
       "      StandardHours  StockOptionLevel  TotalWorkingYears  \\\n",
       "1061             80                 1                  1   \n",
       "891              80                 1                 10   \n",
       "456              80                 1                 10   \n",
       "922              80                 2                 26   \n",
       "69               80                 1                  2   \n",
       "...             ...               ...                ...   \n",
       "1269             80                 0                 10   \n",
       "1352             80                 1                 10   \n",
       "1236             80                 3                 16   \n",
       "1023             80                 1                  5   \n",
       "285              80                 0                 17   \n",
       "\n",
       "      TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
       "1061                      2                3               1   \n",
       "891                       5                3              10   \n",
       "456                       3                2               5   \n",
       "922                       4                2              25   \n",
       "69                        0                2               1   \n",
       "...                     ...              ...             ...   \n",
       "1269                      5                3               9   \n",
       "1352                      5                3               2   \n",
       "1236                      3                3               2   \n",
       "1023                      3                4               3   \n",
       "285                       3                3              17   \n",
       "\n",
       "      YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "1061                   0                        0                     0  \n",
       "891                    5                        7                     7  \n",
       "456                    4                        0                     1  \n",
       "922                    9                       14                    13  \n",
       "69                     0                        0                     0  \n",
       "...                  ...                      ...                   ...  \n",
       "1269                   7                        1                     8  \n",
       "1352                   0                        2                     2  \n",
       "1236                   2                        2                     2  \n",
       "1023                   2                        1                     0  \n",
       "285                   12                        5                     7  \n",
       "\n",
       "[294 rows x 55 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the encoding on testing set\n",
    "X_test_enc = enc.fit_transform(X_test)\n",
    "X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Dealing with unbalanced class using SMOTE\n",
    "\n",
    "We will use the `imblearn` package. Specifically we will use the implemenation found here:\n",
    "\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "\n",
    "To use this package we will `.fit(..)` a SMOTE object using the training set and then call a function called `resample(..)` to generate a new training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Initiate a SMOTE object\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "#Create the new (balanced) training set using SMOTE\n",
    "X_train_enc_res, y_train_res = sm.fit_resample(X_train_enc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    986\n",
       "1    986\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the frequency counts of the output feature in resampled training set\n",
    "\n",
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Implementing Machine Learning Models\n",
    "Having ensured that all categorical values are encoded and the training data are now balanced, we are now ready to proceed onto building our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6a: Implementing Bagging Classifier\n",
    "\n",
    "We'll first implement the **Bagging Classifier**. The document can be found here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In this practical, we focus on tree-based Bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=10),\n",
       "                  n_estimators=100, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the Bagging classifier (BaggingClassifier from sklearn)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Set Bagging parameters\n",
    "baggging_params = {\n",
    "    'base_estimator': DecisionTreeClassifier(max_depth = 10),\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 1.0,\n",
    "    'max_features': 1.0,\n",
    "    'bootstrap': True,\n",
    "    'bootstrap_features': False,\n",
    "    'n_jobs': -1,\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "#Initiate a BaggingClassifier object using the parameters set above\n",
    "bagging = BaggingClassifier(**baggging_params)\n",
    "\n",
    "#Fit the BaggingClassifier object on the resampled training data\n",
    "bagging.fit(X_train_enc_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction on testing data\n",
    "bagging_pred = bagging.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605442176870748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       247\n",
      "           1       0.62      0.32      0.42        47\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.75      0.64      0.67       294\n",
      "weighted avg       0.84      0.86      0.84       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the bagging classifer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, bagging_pred))\n",
    "print(classification_report(y_test, bagging_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try different base_estimator and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the No.1 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.2 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.3 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.4 base estimator: 0.8163265306122449\n",
      "Accuracy score of the No.5 base estimator: 0.8061224489795918\n",
      "Accuracy score of the No.6 base estimator: 0.7755102040816326\n",
      "Accuracy score of the No.7 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.8 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.9 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.10 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.11 base estimator: 0.8027210884353742\n",
      "Accuracy score of the No.12 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.13 base estimator: 0.7993197278911565\n",
      "Accuracy score of the No.14 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.15 base estimator: 0.7414965986394558\n",
      "Accuracy score of the No.16 base estimator: 0.7482993197278912\n",
      "Accuracy score of the No.17 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.18 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.19 base estimator: 0.7993197278911565\n",
      "Accuracy score of the No.20 base estimator: 0.7585034013605442\n",
      "Accuracy score of the No.21 base estimator: 0.7925170068027211\n",
      "Accuracy score of the No.22 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.23 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.24 base estimator: 0.782312925170068\n",
      "Accuracy score of the No.25 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.26 base estimator: 0.7959183673469388\n",
      "Accuracy score of the No.27 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.28 base estimator: 0.717687074829932\n",
      "Accuracy score of the No.29 base estimator: 0.7585034013605442\n",
      "Accuracy score of the No.30 base estimator: 0.8401360544217688\n",
      "Accuracy score of the No.31 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.32 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.33 base estimator: 0.7551020408163265\n",
      "Accuracy score of the No.34 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.35 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.36 base estimator: 0.7448979591836735\n",
      "Accuracy score of the No.37 base estimator: 0.7755102040816326\n",
      "Accuracy score of the No.38 base estimator: 0.7312925170068028\n",
      "Accuracy score of the No.39 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.40 base estimator: 0.7891156462585034\n",
      "Accuracy score of the No.41 base estimator: 0.7755102040816326\n",
      "Accuracy score of the No.42 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.43 base estimator: 0.7857142857142857\n",
      "Accuracy score of the No.44 base estimator: 0.7925170068027211\n",
      "Accuracy score of the No.45 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.46 base estimator: 0.8095238095238095\n",
      "Accuracy score of the No.47 base estimator: 0.7074829931972789\n",
      "Accuracy score of the No.48 base estimator: 0.7857142857142857\n",
      "Accuracy score of the No.49 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.50 base estimator: 0.7789115646258503\n",
      "Accuracy score of the No.51 base estimator: 0.7312925170068028\n",
      "Accuracy score of the No.52 base estimator: 0.7448979591836735\n",
      "Accuracy score of the No.53 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.54 base estimator: 0.7414965986394558\n",
      "Accuracy score of the No.55 base estimator: 0.782312925170068\n",
      "Accuracy score of the No.56 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.57 base estimator: 0.717687074829932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score of the No.58 base estimator: 0.7585034013605442\n",
      "Accuracy score of the No.59 base estimator: 0.7585034013605442\n",
      "Accuracy score of the No.60 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.61 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.62 base estimator: 0.782312925170068\n",
      "Accuracy score of the No.63 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.64 base estimator: 0.7448979591836735\n",
      "Accuracy score of the No.65 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.66 base estimator: 0.7551020408163265\n",
      "Accuracy score of the No.67 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.68 base estimator: 0.7551020408163265\n",
      "Accuracy score of the No.69 base estimator: 0.7619047619047619\n",
      "Accuracy score of the No.70 base estimator: 0.7891156462585034\n",
      "Accuracy score of the No.71 base estimator: 0.7925170068027211\n",
      "Accuracy score of the No.72 base estimator: 0.7653061224489796\n",
      "Accuracy score of the No.73 base estimator: 0.7721088435374149\n",
      "Accuracy score of the No.74 base estimator: 0.7585034013605442\n",
      "Accuracy score of the No.75 base estimator: 0.8061224489795918\n",
      "Accuracy score of the No.76 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.77 base estimator: 0.7278911564625851\n",
      "Accuracy score of the No.78 base estimator: 0.782312925170068\n",
      "Accuracy score of the No.79 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.80 base estimator: 0.7755102040816326\n",
      "Accuracy score of the No.81 base estimator: 0.7959183673469388\n",
      "Accuracy score of the No.82 base estimator: 0.7551020408163265\n",
      "Accuracy score of the No.83 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.84 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.85 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.86 base estimator: 0.7993197278911565\n",
      "Accuracy score of the No.87 base estimator: 0.7959183673469388\n",
      "Accuracy score of the No.88 base estimator: 0.7482993197278912\n",
      "Accuracy score of the No.89 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.90 base estimator: 0.7517006802721088\n",
      "Accuracy score of the No.91 base estimator: 0.7891156462585034\n",
      "Accuracy score of the No.92 base estimator: 0.7414965986394558\n",
      "Accuracy score of the No.93 base estimator: 0.8061224489795918\n",
      "Accuracy score of the No.94 base estimator: 0.7925170068027211\n",
      "Accuracy score of the No.95 base estimator: 0.7687074829931972\n",
      "Accuracy score of the No.96 base estimator: 0.7755102040816326\n",
      "Accuracy score of the No.97 base estimator: 0.7959183673469388\n",
      "Accuracy score of the No.98 base estimator: 0.7925170068027211\n",
      "Accuracy score of the No.99 base estimator: 0.7380952380952381\n",
      "Accuracy score of the No.100 base estimator: 0.7653061224489796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy score of each base estimator\n",
    "index = 1\n",
    "for base_estimator in bagging.estimators_:\n",
    "    print(\"Accuracy score of the No.{} base estimator: {}\".format(index, accuracy_score(y_test, base_estimator.predict(X_test_enc))))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6b: Implementing Adaptive Boosting Classifier\n",
    "\n",
    "Then we implement the **Adaptive Boosting Classifier**. The document can be found here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "**Adaboost** is also a meta-estimator for machine learning. So it's not an actual machine learning model, but rather a way to combine machine learning models. AdaBoost takes an ensemble of other machine learning classifiers (e.g. regression, decision trees, random forests, neural networks) and combines them in a weighted fashion to create a new classifier. So it is like taking several weak predictive models and combining them to form one super model. In this practical, we focus on the tree-based AdaBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
       "                   n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the Adaptive Boosting classifier (AdaBoostClassifier from sklearn)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Set Adaptive Boosting parameters\n",
    "adaBoost_params = {\n",
    "    'base_estimator': DecisionTreeClassifier(max_depth=5),\n",
    "    'n_estimators': 100,\n",
    "    'algorithm': 'SAMME.R',\n",
    "    'learning_rate': 1.0,\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "#Initiate a AdaBoostClassifier object using the parameters set above\n",
    "adaBoost = AdaBoostClassifier(**adaBoost_params)\n",
    "\n",
    "#Fit the AdaBoostClassifier object on the resampled training data\n",
    "adaBoost.fit(X_train_enc_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction on testing data\n",
    "adaBoost_pred = adaBoost.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299319727891157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       247\n",
      "           1       0.46      0.34      0.39        47\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.67      0.63      0.65       294\n",
      "weighted avg       0.81      0.83      0.82       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Adaptive Boosting classifer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, adaBoost_pred))\n",
    "print(classification_report(y_test, adaBoost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DailyRate', nan),\n",
       " ('MonthlyRate', 0.07018875637157854),\n",
       " ('HourlyRate', 0.05458084975935501),\n",
       " ('MonthlyIncome', 0.050477180900378504),\n",
       " ('EmployeeNumber', 0.04935556186874991),\n",
       " ('DistanceFromHome', 0.04913011566352247),\n",
       " ('TotalWorkingYears', 0.044898587189874065),\n",
       " ('Age', 0.044084878824472984),\n",
       " ('PercentSalaryHike', 0.036933523736501835),\n",
       " ('EnvironmentSatisfaction', 0.03561522988157498),\n",
       " ('OverTime_1', 0.0341530352146607),\n",
       " ('YearsWithCurrManager', 0.033972455400375655),\n",
       " ('YearsSinceLastPromotion', 0.030034432784372435),\n",
       " ('WorkLifeBalance', 0.029862214143587678),\n",
       " ('NumCompaniesWorked', 0.02776532672727396),\n",
       " ('JobSatisfaction', 0.024055688316023977),\n",
       " ('EducationField_1', 0.023846356320681564),\n",
       " ('StockOptionLevel', 0.023347573241083542),\n",
       " ('YearsInCurrentRole', 0.021077034806612716),\n",
       " ('Education', 0.020850995118490805),\n",
       " ('RelationshipSatisfaction', 0.020333511738384692),\n",
       " ('TrainingTimesLastYear', 0.018858324385925697),\n",
       " ('YearsAtCompany', 0.0187243004726298),\n",
       " ('JobInvolvement', 0.018572224718586355),\n",
       " ('EducationField_4', 0.015004330325354098),\n",
       " ('MaritalStatus_2', 0.013434242805790603),\n",
       " ('BusinessTravel_1', 0.012662663578081854),\n",
       " ('Department_2', 0.010498806424000457),\n",
       " ('Gender_1', 0.009428485908507745),\n",
       " ('MaritalStatus_3', 0.008185263987359115),\n",
       " ('JobRole_4', 0.0075568576997888815),\n",
       " ('MaritalStatus_1', 0.006888894877751387),\n",
       " ('Gender_2', 0.00651041161258362),\n",
       " ('EducationField_2', 0.005521396236313559),\n",
       " ('JobLevel', 0.005292932460731079),\n",
       " ('EducationField_3', 0.005229948007261113),\n",
       " ('Department_1', 0.004929406661967712),\n",
       " ('BusinessTravel_3', 0.004737092417823071),\n",
       " ('JobRole_3', 0.004733085272714852),\n",
       " ('JobRole_8', 0.004719952084523357),\n",
       " ('JobRole_2', 0.0039411156077689725),\n",
       " ('JobRole_5', 0.0036233950764262474),\n",
       " ('JobRole_6', 0.0034095196746687217),\n",
       " ('EducationField_5', 0.0032522329735477896),\n",
       " ('OverTime_2', 0.0029377569823444295),\n",
       " ('BusinessTravel_2', 0.0027948704566845687),\n",
       " ('JobRole_9', 0.0024300927427408953),\n",
       " ('JobRole_7', 0.0015040115525001205),\n",
       " ('JobRole_1', 0.001285809081193321),\n",
       " ('EducationField_6', 0.0006786374721031823),\n",
       " ('Department_3', 0.0006261846776819723),\n",
       " ('PerformanceRating', 0.00026411579397580496),\n",
       " ('EmployeeCount', 0.0),\n",
       " ('Over18_1', 0.0),\n",
       " ('StandardHours', 0.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the feature importance computed by AdaBoost model\n",
    "\n",
    "feature_importance_dic = {}\n",
    "for i in range(0, len(X_train_enc_res.columns.values)):\n",
    "    feature_importance_dic[X_train_enc_res.columns.values[i]] = adaBoost.feature_importances_[i]\n",
    "\n",
    "# key=lambda x: x[1] 为对前面的对象中的第二维数据（即value）的值进行排序\n",
    "sorted(feature_importance_dic.items(), key=lambda x: x[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of first 1 models: 0.7925170068027211\n",
      "Accuracy score of first 2 models: 0.8163265306122449\n",
      "Accuracy score of first 3 models: 0.7857142857142857\n",
      "Accuracy score of first 4 models: 0.7687074829931972\n",
      "Accuracy score of first 5 models: 0.782312925170068\n",
      "Accuracy score of first 6 models: 0.7857142857142857\n",
      "Accuracy score of first 7 models: 0.8231292517006803\n",
      "Accuracy score of first 8 models: 0.8129251700680272\n",
      "Accuracy score of first 9 models: 0.8027210884353742\n",
      "Accuracy score of first 10 models: 0.8027210884353742\n",
      "Accuracy score of first 11 models: 0.8027210884353742\n",
      "Accuracy score of first 12 models: 0.7891156462585034\n",
      "Accuracy score of first 13 models: 0.7857142857142857\n",
      "Accuracy score of first 14 models: 0.7857142857142857\n",
      "Accuracy score of first 15 models: 0.8027210884353742\n",
      "Accuracy score of first 16 models: 0.7925170068027211\n",
      "Accuracy score of first 17 models: 0.7755102040816326\n",
      "Accuracy score of first 18 models: 0.7789115646258503\n",
      "Accuracy score of first 19 models: 0.7789115646258503\n",
      "Accuracy score of first 20 models: 0.7755102040816326\n",
      "Accuracy score of first 21 models: 0.7687074829931972\n",
      "Accuracy score of first 22 models: 0.7585034013605442\n",
      "Accuracy score of first 23 models: 0.7721088435374149\n",
      "Accuracy score of first 24 models: 0.7585034013605442\n",
      "Accuracy score of first 25 models: 0.7653061224489796\n",
      "Accuracy score of first 26 models: 0.7721088435374149\n",
      "Accuracy score of first 27 models: 0.7789115646258503\n",
      "Accuracy score of first 28 models: 0.7653061224489796\n",
      "Accuracy score of first 29 models: 0.7619047619047619\n",
      "Accuracy score of first 30 models: 0.7653061224489796\n",
      "Accuracy score of first 31 models: 0.7687074829931972\n",
      "Accuracy score of first 32 models: 0.7687074829931972\n",
      "Accuracy score of first 33 models: 0.7721088435374149\n",
      "Accuracy score of first 34 models: 0.7687074829931972\n",
      "Accuracy score of first 35 models: 0.7721088435374149\n",
      "Accuracy score of first 36 models: 0.7755102040816326\n",
      "Accuracy score of first 37 models: 0.7687074829931972\n",
      "Accuracy score of first 38 models: 0.7755102040816326\n",
      "Accuracy score of first 39 models: 0.7857142857142857\n",
      "Accuracy score of first 40 models: 0.7959183673469388\n",
      "Accuracy score of first 41 models: 0.8061224489795918\n",
      "Accuracy score of first 42 models: 0.8027210884353742\n",
      "Accuracy score of first 43 models: 0.7993197278911565\n",
      "Accuracy score of first 44 models: 0.8027210884353742\n",
      "Accuracy score of first 45 models: 0.8061224489795918\n",
      "Accuracy score of first 46 models: 0.8129251700680272\n",
      "Accuracy score of first 47 models: 0.8095238095238095\n",
      "Accuracy score of first 48 models: 0.8027210884353742\n",
      "Accuracy score of first 49 models: 0.8027210884353742\n",
      "Accuracy score of first 50 models: 0.8027210884353742\n",
      "Accuracy score of first 51 models: 0.8095238095238095\n",
      "Accuracy score of first 52 models: 0.8197278911564626\n",
      "Accuracy score of first 53 models: 0.8231292517006803\n",
      "Accuracy score of first 54 models: 0.8197278911564626\n",
      "Accuracy score of first 55 models: 0.8231292517006803\n",
      "Accuracy score of first 56 models: 0.8231292517006803\n",
      "Accuracy score of first 57 models: 0.8095238095238095\n",
      "Accuracy score of first 58 models: 0.826530612244898\n",
      "Accuracy score of first 59 models: 0.8129251700680272\n",
      "Accuracy score of first 60 models: 0.8129251700680272\n",
      "Accuracy score of first 61 models: 0.8095238095238095\n",
      "Accuracy score of first 62 models: 0.8163265306122449\n",
      "Accuracy score of first 63 models: 0.8197278911564626\n",
      "Accuracy score of first 64 models: 0.826530612244898\n",
      "Accuracy score of first 65 models: 0.8299319727891157\n",
      "Accuracy score of first 66 models: 0.8197278911564626\n",
      "Accuracy score of first 67 models: 0.8197278911564626\n",
      "Accuracy score of first 68 models: 0.8095238095238095\n",
      "Accuracy score of first 69 models: 0.8095238095238095\n",
      "Accuracy score of first 70 models: 0.8129251700680272\n",
      "Accuracy score of first 71 models: 0.8129251700680272\n",
      "Accuracy score of first 72 models: 0.8095238095238095\n",
      "Accuracy score of first 73 models: 0.8163265306122449\n",
      "Accuracy score of first 74 models: 0.8129251700680272\n",
      "Accuracy score of first 75 models: 0.8061224489795918\n",
      "Accuracy score of first 76 models: 0.8129251700680272\n",
      "Accuracy score of first 77 models: 0.8163265306122449\n",
      "Accuracy score of first 78 models: 0.8129251700680272\n",
      "Accuracy score of first 79 models: 0.8129251700680272\n",
      "Accuracy score of first 80 models: 0.8129251700680272\n",
      "Accuracy score of first 81 models: 0.8129251700680272\n",
      "Accuracy score of first 82 models: 0.8163265306122449\n",
      "Accuracy score of first 83 models: 0.8197278911564626\n",
      "Accuracy score of first 84 models: 0.8231292517006803\n",
      "Accuracy score of first 85 models: 0.8129251700680272\n",
      "Accuracy score of first 86 models: 0.826530612244898\n",
      "Accuracy score of first 87 models: 0.8197278911564626\n",
      "Accuracy score of first 88 models: 0.8163265306122449\n",
      "Accuracy score of first 89 models: 0.8197278911564626\n",
      "Accuracy score of first 90 models: 0.8163265306122449\n",
      "Accuracy score of first 91 models: 0.8129251700680272\n",
      "Accuracy score of first 92 models: 0.8163265306122449\n",
      "Accuracy score of first 93 models: 0.826530612244898\n",
      "Accuracy score of first 94 models: 0.8197278911564626\n",
      "Accuracy score of first 95 models: 0.826530612244898\n",
      "Accuracy score of first 96 models: 0.8163265306122449\n",
      "Accuracy score of first 97 models: 0.8197278911564626\n",
      "Accuracy score of first 98 models: 0.8231292517006803\n",
      "Accuracy score of first 99 models: 0.826530612244898\n",
      "Accuracy score of first 100 models: 0.8299319727891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinshi/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy score of the prediction on test set after each boost.\n",
    "\n",
    "index = 1\n",
    "for pred in adaBoost.staged_predict(X_test_enc):\n",
    "    print(\"Accuracy score of first {} models: {}\".format(index, accuracy_score(y_test, pred)))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
